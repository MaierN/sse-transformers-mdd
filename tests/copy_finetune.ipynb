{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    RobertaTokenizer,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 425631\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 14634\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 25156\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_from_disk(\"/data/nicolasmaier/dataset/hf_cropped_dataset\")\n",
    "dataset = dataset.remove_columns([\"code\", \"contents\", \"xmi\", \"originalLine\"])\n",
    "#dataset = dataset.with_format(\"torch\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"../models/codet5-finetuned-2\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=10,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    #load_best_model_at_end=True,\n",
    "    #metric_for_best_model=\"EM\", # or BLEU?\n",
    "    report_to=\"tensorboard\",\n",
    "    fp16=True, # train faster\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 425631\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 159612\n",
      "  Number of trainable parameters = 60492288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43001' max='159612' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 43001/159612 5:02:01 < 13:39:04, 2.37 it/s, Epoch 0.81/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.096273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.064490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.052970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.043582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.038370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.031894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.029232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.026426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.022283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.020855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.018802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.017472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.016485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.015617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.015175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.013996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.013457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.012607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.012502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.012272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.011327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.010777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.010157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.009187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.009349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.009007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.008902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.008234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.007962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.008051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.007298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.007228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.007185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.007273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.006780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.006708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.006636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.006685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.006371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.006566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.006002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.005723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.005795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.005523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.005857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.005531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.005513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.005051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.005253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.004937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.004898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.004784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.004761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.004673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.004403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.004608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.004603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.004499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.004670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.004438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.004524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.004269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.004106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.004119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.004067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.004181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.004008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.003875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.003960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.003952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.003775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.004069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.003758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.003761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='555' max='1830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 555/1830 00:31 < 01:12, 17.66 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-1000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-1000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-1000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-1500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-1500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-1500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-2000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-2000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-2000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-2500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-2500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-2500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-3000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-3000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-3000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-3500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-3500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-3500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-4000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-4000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-4000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-4500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-4500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-5000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-5000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-10] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-5500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-5500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-6000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-6000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-6500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-6500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-7000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-7000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-2000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-7500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-7500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-2500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-8000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-8000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-3000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-8500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-8500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-3500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-9000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-9000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-4000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-9500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-9500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-4500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-10000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-10000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-10500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-10500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-5500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-11000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-11000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-6000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-11500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-11500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-6500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-12000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-12000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-7000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-12500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-12500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-7500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-13000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-13000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-8000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-13500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-13500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-8500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-14000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-14000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-9000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-14500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-14500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-9500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-15000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-15000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-15500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-15500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-10500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-16000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-16000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-11000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-16500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-16500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-11500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-17000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-17000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-12000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-17500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-17500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-12500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-18000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-18000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-13000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-18500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-18500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-13500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-19000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-19000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-14000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-19500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-19500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-14500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-20000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-20000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-20500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-20500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-15500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-21000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-21000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-16000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-21500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-21500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-16500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-22000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-22000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-17000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-22500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-22500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-17500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-23000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-23000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-18000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-23500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-23500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-18500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-24000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-24000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-19000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-24500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-24500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-24500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-19500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-25000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-25000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-25500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-25500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-20500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-26000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-26000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-21000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-26500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-26500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-21500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-27000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-27000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-22000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-27500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-27500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-22500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-28000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-28000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-23000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-28500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-28500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-23500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-29000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-29000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-24000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-29500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-29500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-24500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-30000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-30000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-30500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-30500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-25500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-31000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-31000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-26000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-31500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-31500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-26500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-32000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-32000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-27000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-32500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-32500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-27500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-33000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-33000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-28000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-33500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-33500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-28500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-34000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-34000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-29000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-34500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-34500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-29500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-35000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-35000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-35500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-35500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-30500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-36000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-36000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-31000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-36500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-36500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-36500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-31500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-37000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-37000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-32000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-37500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-37500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-32500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-38000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-38000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-33000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-38500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-38500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-38500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-33500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-39000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-39000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-34000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-39500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-39500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-39500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-34500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-40000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-40000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-40500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-40500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-40500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-35500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-41000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-41000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-36000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-41500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-41500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-41500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-36500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-42000\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-42000/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-37000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/codet5-finetuned/checkpoint-42500\n",
      "Configuration saved in ../models/codet5-finetuned/checkpoint-42500/config.json\n",
      "Model weights saved in ../models/codet5-finetuned/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in ../models/codet5-finetuned/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in ../models/codet5-finetuned/checkpoint-42500/special_tokens_map.json\n",
      "Deleting older checkpoint [../models/codet5-finetuned/checkpoint-37500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14634\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1498\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1500\u001b[0m )\n\u001b[0;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1502\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1503\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1504\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1505\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1506\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/trainer.py:1826\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1823\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1826\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1827\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1828\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/trainer.py:2089\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2083\u001b[0m             metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m   2084\u001b[0m                 eval_dataset\u001b[39m=\u001b[39meval_dataset,\n\u001b[1;32m   2085\u001b[0m                 ignore_keys\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2086\u001b[0m                 metric_key_prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meval_\u001b[39m\u001b[39m{\u001b[39;00meval_dataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2087\u001b[0m             )\n\u001b[1;32m   2088\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2089\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[1;32m   2090\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2092\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/trainer_seq2seq.py:78\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m gen_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_beams\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     gen_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_beams\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m gen_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnum_beams\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgeneration_num_beams\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gen_kwargs \u001b[39m=\u001b[39m gen_kwargs\n\u001b[0;32m---> 78\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mevaluate(eval_dataset, ignore_keys\u001b[39m=\u001b[39;49mignore_keys, metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix)\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/trainer.py:2796\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2793\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2795\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2796\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   2797\u001b[0m     eval_dataloader,\n\u001b[1;32m   2798\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   2799\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2800\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2801\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2802\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   2803\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   2804\u001b[0m )\n\u001b[1;32m   2806\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   2807\u001b[0m output\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m   2808\u001b[0m     speed_metrics(\n\u001b[1;32m   2809\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2813\u001b[0m     )\n\u001b[1;32m   2814\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/trainer.py:2974\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2971\u001b[0m         batch_size \u001b[39m=\u001b[39m observed_batch_size\n\u001b[1;32m   2973\u001b[0m \u001b[39m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 2974\u001b[0m loss, logits, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction_step(model, inputs, prediction_loss_only, ignore_keys\u001b[39m=\u001b[39;49mignore_keys)\n\u001b[1;32m   2975\u001b[0m inputs_decode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_input(inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39minclude_inputs_for_metrics \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2977\u001b[0m \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/trainer_seq2seq.py:166\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mPerform an evaluation step on `model` using `inputs`.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m    labels (each being optional).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpredict_with_generate \u001b[39mor\u001b[39;00m prediction_loss_only:\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprediction_step(\n\u001b[1;32m    167\u001b[0m         model, inputs, prediction_loss_only\u001b[39m=\u001b[39;49mprediction_loss_only, ignore_keys\u001b[39m=\u001b[39;49mignore_keys\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    170\u001b[0m has_labels \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m    171\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_inputs(inputs)\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/trainer.py:3217\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3215\u001b[0m \u001b[39mif\u001b[39;00m has_labels:\n\u001b[1;32m   3216\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3217\u001b[0m         loss, outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs, return_outputs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   3218\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m   3220\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/trainer.py:2540\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2539\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2540\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2541\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2542\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:1611\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[39m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1610\u001b[0m     \u001b[39m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1611\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1612\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1613\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1614\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1615\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1616\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1617\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1618\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1619\u001b[0m     )\n\u001b[1;32m   1620\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1621\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1622\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1623\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1624\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1625\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:1040\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1028\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1029\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1040\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1041\u001b[0m         hidden_states,\n\u001b[1;32m   1042\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1043\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1044\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1045\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1046\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1049\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1050\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1051\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1052\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:673\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[1;32m    674\u001b[0m     hidden_states,\n\u001b[1;32m    675\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    676\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    677\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    678\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    679\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    680\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    681\u001b[0m )\n\u001b[1;32m    682\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    683\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:579\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    569\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    570\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m ):\n\u001b[1;32m    578\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 579\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[1;32m    580\u001b[0m         normed_hidden_states,\n\u001b[1;32m    581\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    582\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    583\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    584\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    585\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    586\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    587\u001b[0m     )\n\u001b[1;32m    588\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    589\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:521\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    519\u001b[0m         position_bias\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     position_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_bias(real_seq_length, key_length, device\u001b[39m=\u001b[39;49mscores\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    523\u001b[0m \u001b[39m# if key and values are already calculated\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[39m# we want only the last query position bias\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:428\u001b[0m, in \u001b[0;36mT5Attention.compute_bias\u001b[0;34m(self, query_length, key_length, device)\u001b[0m\n\u001b[1;32m    426\u001b[0m memory_position \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(key_length, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)[\u001b[39mNone\u001b[39;00m, :]\n\u001b[1;32m    427\u001b[0m relative_position \u001b[39m=\u001b[39m memory_position \u001b[39m-\u001b[39m context_position  \u001b[39m# shape (query_length, key_length)\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m relative_position_bucket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_relative_position_bucket(\n\u001b[1;32m    429\u001b[0m     relative_position,  \u001b[39m# shape (query_length, key_length)\u001b[39;49;00m\n\u001b[1;32m    430\u001b[0m     bidirectional\u001b[39m=\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mis_decoder),\n\u001b[1;32m    431\u001b[0m     num_buckets\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelative_attention_num_buckets,\n\u001b[1;32m    432\u001b[0m     max_distance\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelative_attention_max_distance,\n\u001b[1;32m    433\u001b[0m )\n\u001b[1;32m    434\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelative_attention_bias(relative_position_bucket)  \u001b[39m# shape (query_length, key_length, num_heads)\u001b[39;00m\n\u001b[1;32m    435\u001b[0m values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mpermute([\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)  \u001b[39m# shape (1, num_heads, query_length, key_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/sse-transformers-mdd/venv/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:418\u001b[0m, in \u001b[0;36mT5Attention._relative_position_bucket\u001b[0;34m(relative_position, bidirectional, num_buckets, max_distance)\u001b[0m\n\u001b[1;32m    409\u001b[0m relative_position_if_large \u001b[39m=\u001b[39m max_exact \u001b[39m+\u001b[39m (\n\u001b[1;32m    410\u001b[0m     torch\u001b[39m.\u001b[39mlog(relative_position\u001b[39m.\u001b[39mfloat() \u001b[39m/\u001b[39m max_exact)\n\u001b[1;32m    411\u001b[0m     \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39mlog(max_distance \u001b[39m/\u001b[39m max_exact)\n\u001b[1;32m    412\u001b[0m     \u001b[39m*\u001b[39m (num_buckets \u001b[39m-\u001b[39m max_exact)\n\u001b[1;32m    413\u001b[0m )\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m    414\u001b[0m relative_position_if_large \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmin(\n\u001b[1;32m    415\u001b[0m     relative_position_if_large, torch\u001b[39m.\u001b[39mfull_like(relative_position_if_large, num_buckets \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    416\u001b[0m )\n\u001b[0;32m--> 418\u001b[0m relative_buckets \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mwhere(is_small, relative_position, relative_position_if_large)\n\u001b[1;32m    419\u001b[0m \u001b[39mreturn\u001b[39;00m relative_buckets\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "605e098c6041b6083d991721b9f8ec0203cba3209db372356f118eea72c915b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
