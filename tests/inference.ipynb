{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('/data/nicolasmaier/model/codet5-finetuned-split/checkpoint-312000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "model_gpu = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['code', 'contents', 'xmi', 'originalLine', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 425631\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['code', 'contents', 'xmi', 'originalLine', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 14634\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['code', 'contents', 'xmi', 'originalLine', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 25156\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'idx'],\n",
      "        num_rows: 7931293\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'idx'],\n",
      "        num_rows: 255994\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'idx'],\n",
      "        num_rows: 476050\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_from_disk(\"/data/nicolasmaier/dataset/hf_clean_dataset\")\n",
    "dataset_split = load_from_disk(\"/data/nicolasmaier/dataset/hf_split_dataset\")\n",
    "print(dataset)\n",
    "print(dataset_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \n"
     ]
    }
   ],
   "source": [
    "example_orig = dataset[\"test\"][42]\n",
    "input = tokenizer(example_orig[\"contents\"], return_tensors='pt').to(device)\n",
    "\n",
    "#<?xml version=\"1.0\" encoding=\"ASCII\n",
    "prev_outputs = [12880, 2902, 1177, 1546, 21, 18, 20, 6, 2688, 1546, 13756]\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for i in range(50):\n",
    "    print(i, end=' ')\n",
    "    decoder_input = [1] + prev_outputs\n",
    "    outputs = model_gpu.generate(input.input_ids, max_length=801, num_beams=5, early_stopping=True, decoder_input_ids=torch.tensor(decoder_input).unsqueeze(0).to(device))\n",
    "    outputs = outputs[0].tolist()\n",
    "\n",
    "    all_outputs += outputs[1:201]\n",
    "    prev_outputs = outputs[201:]\n",
    "\n",
    "    if model.config.eos_token_id in outputs:\n",
    "        all_outputs += outputs[201:]\n",
    "        print()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_orig = dataset[\"test\"][50]\n",
    "with open('debug_0.txt', 'w') as f:\n",
    "    f.write(example_orig[\"xmi\"])\n",
    "\n",
    "#with open('debug_1.txt', 'w') as f:\n",
    "#    f.write(tokenizer.decode(all_outputs))\n",
    "\n",
    "with open('debug_2.txt', 'w') as f:\n",
    "    f.write(example_orig[\"code\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5610, 1018, 5610, 31, 203, 203, 482, 667, 5916, 797, 288, 203, 565, 632, 6618, 203, 565, 1071, 6320, 1138, 5365, 1253, 4995, 1138, 12, 691, 590, 16, 203, 29159, 514, 29455, 16, 203, 29159, 514, 21522, 16, 203, 29159, 514, 2653, 16, 203, 29159, 514, 3021, 16, 203, 29159, 1525, 1384, 16, 203, 29159, 1525, 1800, 13, 1216, 13367, 288, 203, 3639, 1815, 29455, 480, 446, 31, 203, 3639, 1815, 21522, 480, 446, 31, 203, 3639, 1815, 2653, 480, 446, 31, 203, 3639, 1815, 3021, 480, 446, 31, 203, 203, 3639, 3877, 1339, 273, 7183, 12, 2293, 16, 29455, 16, 21522, 1769, 203, 3639, 2358, 18, 19282, 6560, 18, 78, 3353, 18, 2425, 18, 2271, 18, 1138, 843, 273, 17698, 12, 4923, 16, 3021, 16, 1339, 1769, 203, 3639, 1993, 7800, 6158, 12, 2293, 16, 1339, 18, 24805, 1733, 9334, 843, 1769, 203, 203, 3639, 2358, 18, 19282, 6560, 18, 78, 3353, 18, 2425, 18, 2271, 18, 23583, 563, 273, 843, 18, 338, 7446, 5621, 203, 3639, 514, 4995, 273, 563, 18, 588, 5365, 5621, 203, 3639, 327, 394, 6320, 1138, 5365, 1253, 12, 7088, 16, 3021, 16, 2653, 16, 843, 18, 588, 7469, 1138, 1488, 13742, 10663, 203, 565, 289, 203, 97, 203, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "    @Override\n",
      "    public RestQueryPlanResult planQuery(Request request,\n",
      "                                         String repositoryName,\n",
      "                                         String workspaceName,\n",
      "                                         String language,\n",
      "                                         String statement,\n",
      "                                         long offset,\n",
      "                                         long limit) throws RepositoryException {\n",
      "        assert repositoryName != null;\n",
      "        assert workspaceName != null;\n",
      "        assert language != null;\n",
      "        assert statement != null;\n",
      "\n",
      "        Session session = getSession(request, repositoryName, workspaceName);\n",
      "        org.modeshape.jcr.api.query.Query query = createQuery(language, statement, session);\n",
      "        bindExtraVariables(request, session.getValueFactory(), query);\n",
      "\n",
      "        org.modeshape.jcr.api.query.QueryResult result = query.explain();\n",
      "        String plan = result.getPlan();\n",
      "        return new RestQueryPlanResult(plan, statement, language, query.getAbstractQueryModelRepresentation());\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(dataset[\"train\"]))\n",
    "print(dataset[\"train\"][i][\"input_ids\"], '\\n\\n    ' + dataset[\"train\"][i][\"code\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "605e098c6041b6083d991721b9f8ec0203cba3209db372356f118eea72c915b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
