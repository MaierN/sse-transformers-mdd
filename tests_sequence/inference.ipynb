{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "import torch\n",
    "import random\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('/data/nicolasmaier/model/codet5-finetuned-seq-3/checkpoint-12000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'# 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "model_gpu = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['code', 'contents', 'xmi', 'originalLine', 'input_ids', 'attention_mask', 'seq', 'labels'],\n",
      "        num_rows: 384212\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['code', 'contents', 'xmi', 'originalLine', 'input_ids', 'attention_mask', 'seq', 'labels'],\n",
      "        num_rows: 13488\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['code', 'contents', 'xmi', 'originalLine', 'input_ids', 'attention_mask', 'seq', 'labels'],\n",
      "        num_rows: 22557\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_from_disk(\"/data/nicolasmaier/dataset/hf_clean_seq_dataset\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>private int getRelativeIndex(long pos) {\n",
      "    int currentSize = 0;\n",
      "    currentChunkIndex = 0;\n",
      "\n",
      "    // loop until we find the chuks holding the given position\n",
      "    while (pos >= (currentSize += binaryDataChunks.get(currentChunkIndex).length))\n",
      "      currentChunkIndex++;\n",
      "\n",
      "    currentChunk = binaryDataChunks.get(currentChunkIndex);\n",
      "    currentSize -= currentChunk.length;\n",
      "    // the position referred to the target binary chunk\n",
      "    int relativePosition = (int) (pos - currentSize);\n",
      "    // the index of the first byte to be returned\n",
      "    return relativePosition - 1;\n",
      "  }</s>\n",
      "\n",
      "<s>[{\"type\": \"scopedVariable\", \"name\": \"currentSize\"}, {\"type\": \"methodInvocation\", \"to\": [\"binaryDataChunks\"], \"method\": \"get\"}, {\"type\": \"blocks\", \"blocks\": [{\"name\": \"while\", \"guard\": \"pos >= (currentSize = length)\", \"contents\": []}]}, {\"type\": \"methodInvocation\", \"to\": [\"binaryDataChunks\"], \"method\": \"get\"}, {\"type\": \"scopedVariable\", \"name\": \"relativePosition\"}, \"return\"]</s>\n",
      "\n",
      "<s>[{\"type\": \"scopedVariable\", \"name\": \"currentSize\"}, {\"type\": \"scopedVariable\", \"name\": \"currentChunkIndex\"}, {\"type\": \"methodInvocation\", \"to\": [\"binaryDataChunks\"], \"method\": \"get\"}, {\"type\": \"blocks\", \"blocks\": [{\"name\": \"while\", \"guard\": \"pos >= (currentSize += length)\", \"contents\": []}]}, {\"type\": \"methodInvocation\", \"to\": [\"binaryDataChunks\"], \"method\": \"get\"}, {\"type\": \"scopedVariable\", \"name\": \"relativePosition\"}, \"return\"]</s>\n"
     ]
    }
   ],
   "source": [
    "example_orig = dataset[\"test\"][7212]\n",
    "\n",
    "print(tokenizer.decode(example_orig[\"input_ids\"]))\n",
    "print()\n",
    "print(tokenizer.decode(example_orig[\"labels\"]))\n",
    "print()\n",
    "\n",
    "input = tokenizer(example_orig[\"contents\"], return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model_gpu.generate(\n",
    "    input.input_ids,\n",
    "    num_beams=10,\n",
    "    max_length=510,\n",
    "    # do_sample=True,\n",
    "    temperature=0.3,\n",
    "    top_k=50,\n",
    "    top_p=0.8,\n",
    ")\n",
    "print(tokenizer.decode(outputs[0][1:]))\n",
    "\n",
    "with open(\"diff_out_1.json\", \"w\") as f:\n",
    "    json.dump(json.loads(tokenizer.decode(example_orig[\"labels\"][1:-1])), f, indent=2)\n",
    "with open(\"diff_out_2.json\", \"w\") as f:\n",
    "    json.dump(json.loads(tokenizer.decode(outputs[0][2:-1])), f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "605e098c6041b6083d991721b9f8ec0203cba3209db372356f118eea72c915b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
